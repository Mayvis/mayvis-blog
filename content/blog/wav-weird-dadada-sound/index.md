---
title: Wav weird dadada sound
date: "2023-09-11T12:00:00.000Z"
description: æœ€è¿‘åœ¨ä½¿ç”¨å‰å°é–‹ç™¼è·Ÿè²éŸ³æœ‰é—œçš„åŠŸèƒ½ï¼Œè¦å°‡è²éŸ³è™•ç†å¥½å¾Œï¼Œå‚³åˆ°å¾Œå°è®“ AI åšè§£æï¼Œä½†åœ¨è²éŸ³è™•ç†æ–¹é¢ä¸Šå‡ºäº†é»å•é¡Œï¼Œç”¢å‡ºä¾†çš„éŸ³æª”ä¸€ç›´æœƒæœ‰ dadada çš„è²éŸ³ï¼Œä½¿ç”¨ audacity çš„çš„ç¢ºç¢ºèƒ½çœ‹åˆ°æœ‰ä¸€å€‹å›ºå®šé »ç‡çš„æ–·é»ï¼Œé€™é‚Šè¨˜éŒ„ä¸€ä¸‹è§£æ±ºçš„éç¨‹ã€‚
tags: ["frontend", "backend", "react"]
---

### Audio example

å¯ä»¥è½ä¸€ä¸‹è²éŸ³ï¼Œè²éŸ³æœƒæœ‰ä¸€å€‹å›ºå®šé »ç‡çš„æ–·é»ï¼Œä¸¦ç™¼å‡º dadada çš„è²éŸ³ã€‚

`audio: ../../../src/assets/wav-weird-dadada-sound.wav`

### Frontend

é€™é‚Šæ˜¯å‰å°è™•ç†è²éŸ³çš„éƒ¨åˆ†ï¼Œä½¿ç”¨ audioWorkletï¼Œä¾†é€²è¡Œå°è²éŸ³çš„è™•ç†ï¼Œè½‰æˆ int16 çš„éƒ¨åˆ†æ˜¯å¯ä»¥çœç•¥çš„ã€‚

```ts
// convert processor
class ConvertProcessor extends AudioWorkletProcessor {
  static get parameterDescriptors() {
    return []
  }

  #audioBuffer: Int16Array

  constructor() {
    super()
    this.#audioBuffer = new Int16Array(0)
  }

  convertFloat32ToInt16(inputs: Float32Array[][]) {
    const inputChannelData = inputs[0][0]

    const data = Int16Array.from(inputChannelData, n => {
      const res = n < 0 ? n * 32768 : n * 32767 // convert in range [-32768, 32767]
      return Math.max(-32768, Math.min(32767, res)) // clamp
    })

    const combinedBuffer = new Int16Array(
      this.#audioBuffer.length + data.length
    )
    combinedBuffer.set(this.#audioBuffer, 0)
    combinedBuffer.set(data, this.#audioBuffer.length)

    this.#audioBuffer = combinedBuffer
  }

  sendBuffer() {
    if (this.#audioBuffer.length >= 3200) {
      this.port.postMessage({
        eventType: 'data',
        audioBuffer: this.#audioBuffer,
      })
      this.#audioBuffer = new Int16Array(0) // reset audio buffer
    }
  }

  process(inputs: Float32Array[][]) {
    if (inputs[0].length === 0) {
      console.error('From Convert Processor Worklet, input is null')
      return false
    }

    this.convertFloat32ToInt16(inputs)
    this.sendBuffer()

    return true
  }
}

registerProcessor('convert-processor', ConvertProcessor)

export {}
```

å› ç‚ºè©²å°ˆæ¡ˆä½¿ç”¨ reactï¼Œæ‰€ä»¥æˆ‘ç°¡å–®å¯«äº†ä¸€å€‹ hook ä¾†é€²è¡Œè™•ç†ã€‚

```ts
import { useEffect, useRef, useState, RefObject, useCallback } from 'react'
import ConvertProcessor from '../worker/ConvertProcessor?worker&url'

const SAMPLE_RATE = 16000
const CHANNEL = 1

const useBrowserMedia = (
  browserAudioDeviceRef: RefObject<HTMLSelectElement>
) => {
  const audioContextRef = useRef<AudioContext | null>(null)
  const stream = useRef<MediaStream | null>(null)
  const [browserAudioDevices, setBrowserAudioDevices] = useState<
    MediaDeviceInfo[]
  >([])

  const getUserMediaPermission = async () => {
    return await navigator.mediaDevices.getUserMedia({
      audio: {
        noiseSuppression: false,
        autoGainControl: false,
      },
      video: false,
    })
  }

  const handleStream = async (stream: MediaStream, websocket: WebSocket) => {
    const audioContext = window.AudioContext || window.webkitAudioContext

    if (!audioContextRef.current) {
      audioContextRef.current = new audioContext({
        sampleRate: SAMPLE_RATE,
      })
    }

    const source = audioContextRef.current.createMediaStreamSource(stream)

    try {
      await audioContextRef.current.resume()

      await audioContextRef.current.audioWorklet.addModule(ConvertProcessor)
    } catch (error) {
      throw new Error(`handle stream error: ${error}`)
    }

    const processNode = new AudioWorkletNode(
      audioContextRef.current,
      'convert-processor',
      {
        channelCount: CHANNEL,
      }
    )

    processNode.port.onmessage = e => {
      if (e.data.eventType === 'data') {
        // sending audio buffer to backend
        websocket.send(e.data.audioBuffer.buffer)
      }
    }

    source.connect(processNode).connect(audioContextRef.current.destination)
  }

  const recordFromBrowser = async (deviceId: string, websocket: WebSocket) => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          deviceId: {
            exact: deviceId,
          },
          noiseSuppression: false,
          autoGainControl: false,
        },
        video: false,
      })

      await handleStream(stream, websocket)
    } catch (error) {
      console.log(`record from browser error: ${error}`)
    }
  }

  const stopRecordFromBrowser = () => {
    audioContextRef.current?.close()
    audioContextRef.current = null
  }

  // ç²å–ç€è¦½å™¨éº¥å…‹é¢¨è£ç½®
  useEffect(() => {
    async function getAudioDevices() {
      if (!stream.current) {
        stream.current = await getUserMediaPermission()
      }

      const devices = await navigator.mediaDevices.enumerateDevices()

      const audioInputDevices = devices.filter(
        device => device.kind === 'audioinput'
      )

      if (audioInputDevices.length === 0) return

      setBrowserAudioDevices(audioInputDevices)

      // é‡‹æ”¾æ‰ stream å› ç‚ºåªæ˜¯ä¸€æ¬¡æ€§éœ€ç²å–éº¥å…‹é¢¨æ¬Šé™
      stream.current.getTracks().forEach(track => track.stop())
    }

    getAudioDevices()
  }, [])

  // ç•¶ç€è¦½å™¨éº¥å…‹é¢¨è£ç½®æœ‰è®Šå‹•æ™‚ï¼Œè‡ªå‹•é¸æ“‡ç¬¬ä¸€å€‹è£ç½®
  useEffect(() => {
    if (browserAudioDevices.length === 0 || !browserAudioDeviceRef.current)
      return

    browserAudioDeviceRef.current.value = browserAudioDevices[0].deviceId
  }, [browserAudioDevices, browserAudioDeviceRef])

  return {
    browserAudioDevices,
    recordFromBrowser,
    stopRecordFromBrowser,
  }
}

export default useBrowserMedia
```

### Backend

ç¨‹å¼é–‹å§‹åŸ·è¡Œå¾Œï¼Œ`websocket.send(e.data.audioBuffer.buffer)` æœƒå°‡ buffer é€é websocket é€å¾€å¾Œå°ï¼Œä¸¦ç”±å¾Œå°åšè™•ç†è²éŸ³çš„éƒ¨åˆ†ï¼Œé€™é‚Šæˆ‘æª¢æŸ¥äº†å‰å°çš„ç¨‹å¼ç¢¼ï¼Œæ˜¯æ²’æœ‰å¤ªå¤§å•é¡Œçš„ï¼Œç®—æ˜¯æ»¿æ¨™é…çš„å¯«æ³•ï¼Œé‚£åŸå› æ‡‰è©²å°±æ˜¯å‡ºåœ¨å¾Œå°çš„éƒ¨åˆ†ï¼Œä¸‹æ–¹æ˜¯å¾Œå°æœ€çµ‚èƒ½æ­£å¸¸å„²å­˜è²éŸ³çš„ç¨‹å¼ç¢¼ã€‚

```ts
let fileName: string
let WAV_HEADER: Buffer

function startRecordFromBrowser(
  browserAudioBuffer: ArrayBuffer,
  asrWS: WebSocket,
  wss: Server<typeof WebSocket, typeof IncomingMessage>,
  delayTime: number,
  init: boolean = false
) {
  if (init) {
    createFolder(DIRECTORY)
    fileName = createFileName(DIRECTORY)

    // register file stream in init
    fileStream = fs.createWriteStream(fileName, { encoding: 'binary' })
    fileStream.on('ready', function () {
      console.warn('Ready to write browser record audio to file.')
    })
    fileStream.on('error', function (err) {
      console.warn(
        'An error occurred while writing browser record audio to file: ',
        err
      )
    })
    fileStream.on('finish', function () {
      console.warn('Finished writing browser record audio to file.')
    })

    WAV_HEADER = createWavHeader(browserAudioBuffer.byteLength)
  }

  const audioBufferWithoutWavHeader = Buffer.from(browserAudioBuffer)

  // store audio buffer without wav header
  audioBuffer = Buffer.concat([audioBuffer, audioBufferWithoutWavHeader])

  if (asrWS.readyState === WebSocket.OPEN) {
    asrWS.send(browserAudioBuffer)
  } else {
    console.warn('ASR WebSocket is not open, record close process.')
    fileStream?.end()
    sendCloseWebsocket(wss)
  }
}
```

```ts
const createWavHeader = (dataSize: number) => {
  const SAMPLE_RATE = 16000
  const CHANNEL = 1
  const header = Buffer.alloc(44)

  // Chunk ID "RIFF"
  header.write('RIFF', 0)
  // File size (36 + data size)
  header.writeUInt32LE(36 + dataSize, 4)
  // Format "WAVE"
  header.write('WAVE', 8)
  // Sub-chunk 1 ID "fmt "
  header.write('fmt ', 12)
  // Sub-chunk 1 size (16 for PCM)
  header.writeUInt32LE(16, 16)
  // Audio format (PCM)
  header.writeUInt16LE(1, 20)
  // Number of channels (1 for mono, 2 for stereo)
  header.writeUInt16LE(CHANNEL, 22)
  // Sample rate (e.g., 16000 Hz)
  header.writeUInt32LE(SAMPLE_RATE, 24)
  // Byte rate (SampleRate * NumChannels * BitsPerSample / 8)
  header.writeUInt32LE((SAMPLE_RATE * CHANNEL * 16) / 8, 28)
  // Block align (NumChannels * BitsPerSample / 8)
  header.writeUInt16LE((CHANNEL * 16) / 8, 32)
  // Bits per sample (e.g., 16 bits)
  header.writeUInt16LE(16, 34)
  // Sub-chunk 2 ID "data"
  header.write('data', 36)
  // Sub-chunk 2 size (data size)
  header.writeUInt32LE(dataSize, 40)

  return header
}
```

ğŸš€æœ€å¾Œç™¼ç¾é‚£å€‹ dadada èµ·æ€ªçš„åŸå› æ˜¯å› ç‚ºæˆ‘å°‡ `browserAudioBuffer` å®šç¾©ç‚º Buffer çš„å‹åˆ¥ï¼Œè€Œä¸æ˜¯ ArrayBuffer çš„å‹åˆ¥ï¼Œé–“æ¥å°è‡´ wav header åœ¨è¨ˆç®—æ™‚å‡ºç¾éŒ¯èª¤ï¼Œè¦ä½¿ç”¨ byteLengthï¼Œè€Œä¸æ˜¯ lengthã€‚

### Conclusion

å…¶å¯¦é€™å€‹å•é¡ŒèŠ±äº†æˆ‘ç›¸ç•¶å¤šçš„æ™‚é–“å» debugï¼Œä¹Ÿåœ¨è¤‡ç¿’äº†ä¸€æ¬¡ ArrayBuffer (int16array, uint8array...etcï¼Œå„²å­˜ binary data çš„å®¹å™¨ï¼Œå¯ä»¥é€éè¦–åœ–é€²è¡Œæ“ä½œ) åŠ Buffer (ç”¨æ–¼æ“ä½œ ArrayBuffer çš„è¦–åœ– DataView) ä¹‹é–“çš„å·®åˆ¥ã€‚

æ›´ç´°ç¯€çš„éƒ¨åˆ†å¯ä»¥åƒè€ƒé€™ç¯‡é˜®ä¸€å³°å¯«çš„[æ–‡ç« ](http://javascript.ruanyifeng.com/stdlib/arraybuffer.html)ã€‚
